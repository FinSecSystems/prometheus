version: '3.4'

services:

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus/:/etc/prometheus/
      - ${DATA_DIR}/prometheus:/prometheus:rw
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    depends_on:
      - prometheus-cadvisor
    restart: always
    env_file:
      - ./prometheus.env
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.2
        aliases:
          - prometheus
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.role == manager
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  prometheus-node-exporter:
    image: prom/node-exporter
    container_name: prometheus-node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    dns: ${DNS_IP}
    external_links:
      - dns
    command: 
      - '--path.procfs=/host/proc' 
      - '--path.sysfs=/host/sys'
      - --collector.filesystem.ignored-mount-points
      - "^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)"
    restart: always
    deploy:
      mode: global
    env_file:
      - ./prometheus.env
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.3
        aliases:
          - prometheus-node-exporter
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  prometheus-alertmanager:
    image: prom/alertmanager
    container_name: prometheus-alertmanager
    #    dns: ${DNS_IP}
    #   external_links:
    #   - dns
    volumes:
      - "./alertmanager/:/etc/alertmanager/"
    networks:
      - monitor-net
    restart: always
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    env_file:
      - ./prometheus.env
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.4
        aliases:
          - prometheus-alertmanager
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.role == manager
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  prometheus-cadvisor:
    image: google/cadvisor
    container_name: prometheus-cadvisor
    dns: ${DNS_IP}
    external_links:
      - dns
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    restart: always
    deploy:
      mode: global
    env_file:
      - ./prometheus.env
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.5
        aliases:
          - prometheus-cadvisor
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  grafana:
    image: grafana/grafana
    container_name: grafana
    dns: ${DNS_IP}
    external_links:
      - dns
    depends_on:
      - prometheus
    volumes:
      - ${DATA_DIR}/grafana:/var/lib/grafana:rw
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./grafana/ldap.toml:/etc/grafana/ldap.toml
    env_file:
      - ./grafana/config.monitoring
    restart: always
    env_file:
      - ./prometheus.env
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.6
        aliases:
          - grafana
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  proxy-grafana:
    build: ./proxy-grafana
    image: registry.liquibrium.com/proxy-grafana
    container_name: grafana-proxy
    dns: ${DNS_IP}
    external_links:
      - container-registry
      - dns
    depends_on:
      - grafana
    environment:
      VIRTUAL_HOST: monitor.liquibrium.local
      NETWORK_ACCESS: internal
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.7
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.labels.proxy == true
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  proxy-prometheus:
    build: ./proxy-prometheus
    image: registry.liquibrium.com/proxy-prometheus
    container_name: prometheus-proxy
    dns: ${DNS_IP}
    external_links:
      - container-registry
      - dns
    depends_on:
      - prometheus
    environment:
      VIRTUAL_HOST: prometheus.liquibrium.local
      NETWORK_ACCESS: internal
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.8
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.labels.proxy == true
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  proxy-node-stats:
    build: ./proxy-node-stats
    image: registry.liquibrium.com/proxy-node-stats
    container_name: prometheus-node-stats
    dns: ${DNS_IP}
    external_links:
      - container-registry
      - dns
    depends_on:
      - prometheus-node-exporter
    environment:
      VIRTUAL_HOST: node-stats.liquibrium.local
      NETWORK_ACCESS: internal
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.9
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.labels.proxy == true
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  proxy-alertmanager:
    build: ./proxy-alertmanager
    image: registry.liquibrium.com/proxy-alertmanager
    container_name: prometheus-alertmanager
    dns: ${DNS_IP}
    external_links:
      - container-registry
      - dns
    depends_on:
      - prometheus-alertmanager
    environment:
      VIRTUAL_HOST: alertmanager.liquibrium.local
      NETWORK_ACCESS: internal
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.10
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.labels.proxy == true
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  proxy-cadvisor:
    build: ./proxy-cadvisor
    image: registry.liquibrium.com/proxy-cadvisor
    container_name: prometheus-cadvisor
    dns: ${DNS_IP}
    external_links:
      - container-registry
      - dns
    depends_on:
      - prometheus-cadvisor
    environment:
      VIRTUAL_HOST: cadvisor.liquibrium.local
      NETWORK_ACCESS: internal
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.11
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.labels.proxy == true
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  alertmanager-bot:
    image: metalmatze/alertmanager-bot:0.4.0
    container_name: alertmanager-bot
    external_links:
      - container-registry
    environment:
      ALERTMANAGER_URL: http://prometheus-alertmanager:9093
      BOLT_PATH: /data/bot.db
      STORE: bolt
      TEMPLATE_PATHS: /templates/default.tmpl
    env_file:
      - ./prometheus.env
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.12
        aliases:
          - alertmanager-bot
    volumes:
    - ${DATA_DIR}/alertmanager-bot:/data

  blackbox-exporter:
    image: prom/blackbox-exporter
    container_name: prometheus
    dns: ${DNS_IP}
    external_links:
      - dns
    volumes:
      - ./blackbox-exporter:/config
    command:
      - '--config.file=/config/blackbox.yml'
    depends_on:
      - prometheus
    restart: always
    env_file:
      - ./prometheus.env
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.13
        aliases:
          - blackbox-exporter
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
            #    logging:
            #      driver: "fluentd"
            #      options:
            #        tag: "{{.Name}}.{{.ID}}"
            #        fluentd-async-connect: "true"

  proxy-blackbox:
    build: ./proxy-blackbox
    image: registry.liquibrium.com/proxy-blackbox
    container_name: proxy-blackboxr
    dns: ${DNS_IP}
    external_links:
      - container-registry
      - dns
    depends_on:
      - blackbox-exporter
    environment:
      VIRTUAL_HOST: blackbox-exporter.liquibrium.local
      NETWORK_ACCESS: internal
    networks:
      operations_intranet:
        ipv4_address: 172.30.23.14
    deploy:
      placement:
        constraints:
          - node.labels.type == intranet
          - node.labels.proxy == true

networks:
  operations_intranet:
    external: true

